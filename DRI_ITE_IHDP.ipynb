{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa667681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd812c390d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import models\n",
    "import utility\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn    \n",
    "from torch.autograd import Function\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e016a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs=5000\n",
    "batch_size=256\n",
    "hid_y=100\n",
    "BCE=nn.BCELoss()\n",
    "MSE=nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20519458",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss=[]\n",
    "tr_pehe=[]\n",
    "val_pehe=[]\n",
    "reg_loss_tr=[]\n",
    "classT_loss_tr=[]\n",
    "classW_loss_tr=[]\n",
    "wasser_loss_tr=[]\n",
    "rc_loss=[]\n",
    "OR_reg_li=[]\n",
    "\n",
    "val_reg_li=[]\n",
    "val_tloss_li=[]\n",
    "val_wasser_li=[]\n",
    "val_rec_li=[]\n",
    "\n",
    "def train_CFR(x_data,y_data):\n",
    "   \n",
    "    torch.manual_seed(0)\n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_val_loss = np.inf\n",
    "    min_val_pehe=np.inf\n",
    "    epochs_without_improvement = 0\n",
    "    #threshold=0.00001\n",
    "    patience=400\n",
    "    #x_data,y_data=get_data('train',1)\n",
    "    X_train, X_val,y_train, y_val = train_test_split(x_data,y_data ,\n",
    "                                       random_state=42, \n",
    "                                       test_size=0.20)\n",
    "    # write input_feature instead of 25\n",
    "    net=models.TarNet(input_features,lat_dim,.1)\n",
    "    #wnet=Wclassifier(lat_dim,.1)\n",
    "    tnet=models.Tclassifier(lat_dim*2,.1)\n",
    "    rnet=models.Regressors(lat_dim*2,hid_y,.1)\n",
    "    dnet=models.Decoder(lat_dim*4,input_features,.1)\n",
    "    net.to(device)\n",
    "    tnet.to(device)\n",
    "    rnet.to(device)\n",
    "    dnet.to(device)\n",
    "    \n",
    "    opt_net = torch.optim.Adam(net.parameters(), lr=0.00002,weight_decay=1e-3)#1e-4\n",
    "    opt_nett = torch.optim.Adam(tnet.parameters(), lr=0.00002, weight_decay=1e-3)\n",
    "    opt_netr = torch.optim.Adam(rnet.parameters(), lr=0.00002,weight_decay=1e-3)\n",
    "    opt_netd = torch.optim.Adam(dnet.parameters(), lr=0.00002,weight_decay=1e-3) #,weight_decay=1e-4\n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "    for ep in range(1,epochs+1 ):\n",
    " \n",
    "        train_dataloader_sr, train_dataloader_tr=utility.get_dataloader(X_train,y_train,batch_size)\n",
    "        tot_los=0\n",
    "        reg_los=0\n",
    "        t_los=0\n",
    "        w_los=0\n",
    "        wa_los=0\n",
    "        rc_los=0\n",
    "        rereg_los=0\n",
    "        cnt=0\n",
    " \n",
    "        for batch_idx, (train_source_data, train_target_data) in enumerate(zip(train_dataloader_sr, train_dataloader_tr)):\n",
    "            \n",
    "            xs,ys=train_source_data\n",
    "            xt,yt=train_target_data\n",
    "            # Replace 30 with :\n",
    "            xs_train=xs[:,5:].to(device)\n",
    "            xt_train=xt[:,5:].to(device)\n",
    "            ys.to(device)\n",
    "            yt.to(device)\n",
    "            train_x=torch.cat((xs_train,xt_train),0)\n",
    "            train_y=torch.unsqueeze(torch.cat((ys,yt),0), dim=1).to(device)\n",
    "            true_t=torch.unsqueeze(torch.cat((xs[:,0],xt[:,0]),0), dim=1).to(device)\n",
    "            concat_true=torch.cat((train_y,true_t),1)\n",
    "            prop_t1=(xt_train.shape[0]/train_x.shape[0])\n",
    "            phi_gamma,phi_delta,phi_upsilon,phi_irr=net(train_x)\n",
    "            phi_all=torch.cat((phi_gamma,phi_delta,phi_upsilon,phi_irr), 1)\n",
    "            del_ups=torch.cat((phi_delta, phi_upsilon), 1)\n",
    "            gam_del=torch.cat((phi_gamma,phi_delta), 1)\n",
    "            \n",
    "            concat_pred=rnet(del_ups)\n",
    "            #w_f=wnet(phi_delta)\n",
    "            w_t=tnet(gam_del)\n",
    "            decoded_space=dnet(phi_all)\n",
    "            \n",
    "            predicted_y=torch.unsqueeze(torch.where(true_t.squeeze() == 0, concat_pred[:,0], concat_pred[:,1]),dim=1)\n",
    "            opt_net.zero_grad()\n",
    "           \n",
    "            opt_nett.zero_grad()\n",
    "            opt_netr.zero_grad()\n",
    "            opt_netd.zero_grad()\n",
    "        \n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "         \n",
    "            Rloss=MSE(predicted_y,train_y)\n",
    "           \n",
    "            Reconstruction_loss=(MSE(decoded_space[:,0:6],train_x[:,0:6])+BCE(decoded_space[:,6:25],train_x[:,6:25])+MSE(decoded_space[:,25:],train_x[:,25:]))\n",
    "            \n",
    "            Wassloss,dist=utility.wasserstein(phi_upsilon,true_t)\n",
    "           \n",
    "            Tloss=BCE(w_t, true_t)\n",
    "            cnt=cnt+1\n",
    "            \n",
    "            \n",
    "        \n",
    "            w1,w2,w3,w4=utility.cal_weightmatr(net)\n",
    "            OR=utility.cal_RO(w1,w2,w3,w4)\n",
    "            OR_re=utility.OR_reg(w1,w2,w3,w4)\n",
    "            OR_loss=OR+OR_re\n",
    "           \n",
    "            combined_loss=Rloss+(Wassloss)+(Tloss)+(5*OR)+(OR_re)+(Reconstruction_loss)\n",
    "            \n",
    "            combined_loss.backward()\n",
    "            tot_los=tot_los+combined_loss.item()\n",
    "            reg_los=reg_los+Rloss.item()\n",
    "            t_los=t_los+Tloss.item()\n",
    "            w_los=w_los+OR.item()\n",
    "            wa_los=wa_los+Wassloss.item()\n",
    "            rc_los=rc_los+Reconstruction_loss.item()\n",
    "            rereg_los=rereg_los+OR_re.item()\n",
    "            # optimize\n",
    "            \n",
    "            \n",
    "            opt_net.step()\n",
    "           \n",
    "            opt_nett.step()\n",
    "            opt_netr.step()\n",
    "            opt_netd.step()\n",
    "            \n",
    "            \n",
    "\n",
    "      \n",
    "        val_PEHE=utility.cal_pehe_nn(X_val, y_val,rnet,net)\n",
    "        tr_PEHE=utility.cal_pehe(X_train,y_train,rnet,net)\n",
    "\n",
    "\n",
    "         \n",
    "        # Evaluation of validation\n",
    "        \n",
    "        X_val_t=X_val.to_numpy()\n",
    "        X_val_t=torch.from_numpy(X_val_t.astype(np.float32)).to(device)\n",
    "        \n",
    "        y_val_t=y_val.to_numpy()\n",
    "        y_val_t=torch.from_numpy(y_val_t.astype(np.float32)).to(device)\n",
    "        \n",
    "       \n",
    "        \n",
    "        if (ep>1000):\n",
    "            \n",
    "            if (val_PEHE<min_val_pehe):\n",
    "                min_val_pehe=val_PEHE\n",
    "                torch.save(net.state_dict(), 'best_encoder.pth')\n",
    "                torch.save(rnet.state_dict(), 'best_regressor.pth')\n",
    "                #print(ep)\n",
    "\n",
    "\n",
    "            if (val_PEHE < best_val_loss):\n",
    "                best_val_loss = val_PEHE\n",
    "                epochs_without_improvement = 0\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "\n",
    "            \"\"\"\n",
    "            if (epochs_without_improvement >= patience): #\n",
    "                #print(\"Early stopping: Validation loss did not improve for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "            \"\"\"\n",
    "        \n",
    "        reg_loss_tr.append(reg_los)\n",
    "        classT_loss_tr.append(t_los)\n",
    "        classW_loss_tr.append(w_los)\n",
    "        wasser_loss_tr.append(wa_los)\n",
    "        total_loss.append(tot_los)\n",
    "        tr_pehe.append(tr_PEHE)\n",
    "        val_pehe.append(val_PEHE)\n",
    "        rc_loss.append(rc_los)\n",
    "        OR_reg_li.append(rereg_los)\n",
    "\n",
    "    return rnet,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e031f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent dimensions 5\n",
      "files completed:  1\n",
      "Dummies shuffling:  5\n",
      "PEHE mean 0.8146402835845947\n",
      "PEHE std 0.0\n",
      "*************************************************\n",
      "___________________________Next dimension_______________________________\n"
     ]
    }
   ],
   "source": [
    "lat_dim_li=[5]\n",
    "dummy_list=[5]# 0,5,10,15,20,25\n",
    "for ldi,ld in enumerate(lat_dim_li):\n",
    "    lat_dim=ld\n",
    "    print('latent dimensions', lat_dim)\n",
    "    for di,d in enumerate(dummy_list):\n",
    "    \n",
    "        \n",
    "        pehe_l=[]\n",
    "        dummies=d\n",
    "        input_features=25+dummies\n",
    "        for i in range(1,2):\n",
    "            clean()\n",
    "            x_data_tr,y_data_tr=utility.get_data('train',i)\n",
    "            x_data_n=utility.add_dummy_features_shuffle(x_data_tr,dummies)\n",
    "            Regressor,Encoder=train_CFR(x_data_n,y_data_tr)\n",
    "            \n",
    "            \n",
    "            #_______________loading best models\n",
    "            Enc=models.TarNet(input_features,lat_dim,.1)\n",
    "            Enc.to(device)\n",
    "            Reg=models.Regressors(lat_dim*2,hid_y,.1)\n",
    "            Reg.to(device)\n",
    "            Enc.load_state_dict(torch.load('best_encoder.pth'))\n",
    "            Reg.load_state_dict(torch.load('best_regressor.pth'))\n",
    "            #____________________________\n",
    "    \n",
    "            data,y=utility.get_data('test',i)\n",
    "            data_n=utility.add_dummy_features_shuffle(data,dummies)\n",
    "            pehe_l.append(utility.cal_pehe(data_n,y,Reg,Enc))\n",
    "            print('files completed: ',i)\n",
    "    \n",
    "    \n",
    "        print('Dummies shuffling: ',d)\n",
    "        print('PEHE mean', np.mean(pehe_l))\n",
    "        print('PEHE std', np.std(pehe_l))\n",
    "        print('*************************************************')\n",
    "    print('___________________________Next dimension_______________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe16dc-cbb9-48b4-a480-4973c42d6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clean():\n",
    "    total_loss.clear()\n",
    "    reg_loss_tr.clear()\n",
    "    classT_loss_tr.clear()\n",
    "    classW_loss_tr.clear()\n",
    "    wasser_loss_tr.clear()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
